{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907e810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\selin\\anaconda3\\lib\\site-packages (0.27.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\selin\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\selin\\anaconda3\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\selin\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae169ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\selin\\anaconda3\\lib\\site-packages (0.27.2)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\selin\\anaconda3\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\selin\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\selin\\anaconda3\\lib\\site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\selin\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3367ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65a6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"finetune.json\", \"r\") as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7665058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'What type of music do you like?',\n",
       "  'completion': 'I like to listen to pop music and classical music. How about you?'},\n",
       " {'prompt': 'What kind of exercise do you think is the healthiest?',\n",
       "  'completion': 'I think swimming and jogging are among the healthiest forms of exercise. How about you?'},\n",
       " {'prompt': 'What countries have you traveled to?',\n",
       "  'completion': 'I have traveled to countries such as France, Italy, Japan, and the United States. How about you?'},\n",
       " {'prompt': 'What are your hobbies and interests?',\n",
       "  'completion': 'I enjoy reading, traveling, and listening to music. How about you?'},\n",
       " {'prompt': 'What do you think is the best way to learn a foreign language?',\n",
       "  'completion': 'I think learning a foreign language requires listening, reading, speaking, and writing, as well as interacting with people who speak the language as their native tongue. How about you?'},\n",
       " {'prompt': \"What is a good movie you've seen recently?\",\n",
       "  'completion': 'I recently watched a classic movie called The Shawshank Redemption, which was very moving. How about you?'},\n",
       " {'prompt': 'What types of movies do you like?',\n",
       "  'completion': 'I like sci-fi, action, and thriller movies, among others. How about you?'},\n",
       " {'prompt': 'What do you think is the best method of education?',\n",
       "  'completion': 'I think inquiry-based and hands-on teaching are among the best methods of education. How about you?'},\n",
       " {'prompt': 'What is your favorite holiday?',\n",
       "  'completion': 'My favorite holiday is Christmas because I get to spend time with my family and friends in a warm atmosphere. How about you?'},\n",
       " {'prompt': 'What types of food do you like to eat?',\n",
       "  'completion': 'I like various types of food such as Chinese cuisine, Japanese food, and Italian pasta. How about you?'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6f05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_TUNED_MODEL = \"text-davinci-003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbed6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 10 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- All prompts end with suffix `?`\n",
      "- All prompts start with prefix `What `\n",
      "- All completions end with suffix `. How about you?`. This suffix seems very long. Consider replacing with a shorter suffix, such as `\\n`\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `finetune_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"finetune_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `?` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\". How about you?\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 2.58 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f finetune.json -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87202aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mError:\u001b[0m No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t \"finetune_prepared (1).jsonl\" --batch_size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371f3237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mError:\u001b[0m No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i ft-wtZMNV8B7WcifsTlSvmJjv2r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "421a0abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mError:\u001b[0m No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd55252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_qa = \"curie:ft-pecu-2023-03-09-18-23-42\"\n",
    "def apply_ft_qa_answer(context, question, answering_model):\n",
    "    prompt = f\"{context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    result = openai.Completion.create(model=answering_model, prompt=prompt, max_tokens=30, temperature=0, top_p=1, n=1, stop=['.','\\n'])\n",
    "    return result['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf568457",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'Christmas is an annual festival commemorating the birth of Jesus Christ, observed primarily on December 25 as a religious and cultural celebration among billions of people around the world.'\n",
    "question = 'What is the most popular holiday?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "358f30ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8516\\1968699929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mapply_ft_qa_answer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mft_qa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8516\\1270572665.py\u001b[0m in \u001b[0;36mapply_ft_qa_answer\u001b[1;34m(context, question, answering_model)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_ft_qa_answer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswering_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{context}\\nQuestion: {question}\\nAnswer:\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0manswering_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'choices'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__prepare_create_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_base\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morganization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36m__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timeout\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMAX_TIMEOUT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         requestor = api_requestor.APIRequestor(\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mapi_base\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    128\u001b[0m     ):\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi_base\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_api_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         self.api_type = (\n\u001b[0;32m    132\u001b[0m             \u001b[0mApiType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\util.py\u001b[0m in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         raise openai.error.AuthenticationError(\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[1;34m\"No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions."
     ]
    }
   ],
   "source": [
    "apply_ft_qa_answer(context, question, ft_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfa939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
